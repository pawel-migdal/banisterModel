{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import optimize \n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('workouts.csv')\n",
    "data.describe()\n",
    "Actual_Performance = data['IF']\n",
    "Offset_Performance = []\n",
    "for i in range(len(Actual_Performance)):\n",
    "    Offset_Performance.append(np.mean(Actual_Performance[i: (i+28)])) \n",
    "TSS = data['TSS']\n",
    "Block_TSS = [] \n",
    "for i in range(len(TSS)):\n",
    "    avg_TSS = np.mean(TSS[i:(i+28)])\n",
    "    Block_TSS.append(avg_TSS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vo2_if_bike(row, max_hr, resting_hr, weight) :\n",
    "    if row['WorkoutType'] == 'Bike':\n",
    "        percent_vo2 = (row['HeartRateAverage'] - resting_hr) / (max_hr - resting_hr)\n",
    "        vo2_power = row['PowerAverage'] / percent_vo2\n",
    "        vo2_estimated = (((vo2_power)/75)*1000)/weight\n",
    "        return vo2_estimated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_banister(params):\n",
    "    data = pd.read_csv('workouts.csv')\n",
    "    data['day_TSS'] = data['TSS'].groupby(data['WorkoutDay']).transform('sum') #Fill in any missing days with zero\n",
    "    data['day_TSS'] = data['day_TSS'].fillna(0) #Fill in any missing days with zero\n",
    "    data['bike_V02'] = data.apply(lambda row: calc_vo2_if_bike(row, 196, 50, 74), axis=1) #Calculate VO2 for each bike workout\n",
    "    data = data[['WorkoutDay', 'day_TSS', 'bike_V02']] #Keep only the columns we need\n",
    "    data = data.groupby('WorkoutDay').mean() #Group by day and take the mean of the TSS and VO2\n",
    "    data['WorkoutDate'] = data.index #Add a column for the date\n",
    "    data['WorkoutDate'] = pd.to_datetime(data['WorkoutDate']) #Convert the date column to a datetime object\n",
    "    data = data.sort_values(by=['WorkoutDate']) #Sort the data by date\n",
    "    data.index = pd.DatetimeIndex(data['WorkoutDate']) #Set the index to the date\n",
    "    missing_dates = pd.date_range(start=data.index.min(), end=data.index.max()) #Create a list of all the dates in the range\n",
    "    data = data.reindex(missing_dates, fill_value=0) #Add missing dates\n",
    "    data['bike_V02'] = data['bike_V02'].fillna(method=\"ffill\") #FiLL missing VOZ values with previous value\n",
    "    data = data.dropna() #Drop any remaining rows with missing values TSS= data['day_TSS'].to_list() #Convert the TSS column to a list\n",
    "    TSS = data['day_TSS'].to_list() #Convert the TSS column to a list\n",
    "    Performance = data['bike_V02'].to_list() #Convert the V02 column to a list\n",
    "    losses = [] #Create an empty list to store the loss values from our model\n",
    "    ctls = [0] #Create an empty list to store the CTL values from our model with starting CTL of 0\n",
    "    atls = [0] #Create an empty list to store the ATL values from our model with starting ATL of 0 for i in range(len(TSS)):\n",
    "    for i in range(len(TSS)):\n",
    "        ctl = (TSS[i] * (1-math.exp(-1/params[3]))) + (ctls[i] * (math.exp(-1/params[3]))) #Calculate the CTL for the day\n",
    "        atl = (TSS[i] * (1-math.exp(-1/params[4]))) + (atls[i] * (math.exp(-1/params[4]))) #Calculate the ATL for the day\n",
    "        ctls.append(ctl) #Add the CTL to the list\n",
    "        atls.append(atl) #Add the ATL to the List\n",
    "        Banister_Prediction = params[2] + params[0]*ctl - params[1]*atl #Calculate the Banister Prediction for the day\n",
    "        loss = abs(Performance[i]- Banister_Prediction)\n",
    "        losses.append(loss) #Add the loss to the list\n",
    "    # print(f\"CTLs: {ctls}\")\n",
    "    # print(f\"ATLS: {atls}\")\n",
    "    MAE= np.mean(losses) #Calculate the mean absolute error\n",
    "    # print(f\"MAE: {MAE}\")\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 4.039287638445985\n",
      " hess_inv: <5x5 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 0.80849452, -0.23379281,  0.08571436,  0.00119105,  0.00272697])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 426\n",
      "      nit: 13\n",
      "     njev: 71\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.09719483,  0.15562943, 49.99895401, 39.98851172, 15.04958741])\n",
      "[57.281739130434794, 57.57434782608696, 57.28217391304348, 56.01739130434782, 55.74521739130433, 58.35708333333332, 56.831666666666656, 57.107916666666654, 57.270833333333336, 59.6856, 59.00807692307693, 59.00807692307693, 59.040740740740745, 58.70407407407407, 62.684814814814814, 61.27346153846155, 62.284400000000005, 61.50240000000001, 61.93120000000001, 63.918, 65.06208333333335, 62.82708333333334, 65.46708333333333, 62.41041666666666, 62.73208333333332, 63.838695652173904, 60.6691304347826, 60.62608695652173, 60.85956521739129, 59.76782608695652, 64.01608695652173, 62.37260869565217, 63.31086956521739, 60.458260869565216, 60.184347826086956, 60.30090909090909, 65.645, 61.8140909090909, 65.70181818181817, 65.5491304347826, 64.84347826086956, 67.51434782608695, 63.15, 63.15, 63.99125, 65.46130434782609, 65.49272727272728, 63.80909090909092, 63.80909090909092, 62.67363636363637, 59.20136363636364, 59.77454545454546, 59.43714285714286, 59.57181818181819, 60.37428571428572, 61.86190476190478, 63.72809523809525, 65.028, 61.915789473684214, 62.2278947368421, 62.75631578947369, 63.30833333333333, 70.01888888888888, 70.01888888888888, 63.18388888888889, 66.42, 62.82117647058823, 61.66647058823529, 64.28764705882354, 59.351176470588236, 60.39375, 61.88882352941176, 62.27882352941177, 62.27882352941177, 63.50388888888889, 64.545, 62.392105263157895, 62.92947368421053, 68.76368421052632, 68.14, 67.821, 66.179, 67.62238095238095, 67.40571428571427, 68.80095238095237, 66.98045454545453, 65.8286956521739, 64.93478260869566, 63.61043478260869, 66.05166666666666, 61.39166666666667, 60.91480000000001, 64.12960000000001, 62.292400000000015, 62.28807692307694, 65.45692307692309, 63.03346153846156, 66.01615384615387, 65.82185185185187, 63.70666666666668, 65.14777777777779, 63.66214285714286, 60.91285714285715, 60.92250000000001, 61.588571428571434, 62.37888888888888, 57.86555555555555, 59.02962962962962, 61.37222222222222, 61.15333333333332, 60.66296296296296, 59.49481481481481, 55.96259259259259, 57.97962962962964, 57.56333333333334, 57.12074074074075, 57.47703703703704, 54.007407407407406, 53.54962962962963, 53.70653846153845, 50.786538461538456, 52.19115384615384, 51.65576923076923, 48.041923076923084, 50.20692307692309, 48.1223076923077, 46.189615384615394, 46.90346153846155, 43.47269230769231, 44.97307692307693, 46.79923076923077, 45.42730769230768, 48.2676923076923, 48.2676923076923, 50.396923076923066, 48.41884615384615, 45.48807692307692, 45.82153846153846, 47.26615384615384, 47.27192307692307, 46.35423076923076, 44.61576923076923, 44.62884615384615, 45.46307692307692, 46.056153846153855, 46.76076923076924, 47.742692307692316, 48.8925925925926, 50.13407407407408, 48.685185185185176, 49.66518518518519, 49.44777777777777, 46.63740740740741, 48.245925925925924, 49.3511111111111, 49.80629629629629, 48.70703703703703, 48.28925925925925, 50.05703703703703, 50.17481481481481, 49.00407407407407, 48.93, 48.21892857142858, 49.90178571428572, 49.08392857142858, 49.78250000000001, 45.93857142857144, 46.23750000000001, 48.48035714285715, 49.83107142857143, 52.421428571428564, 51.23500000000001, 52.829285714285696, 52.74214285714284, 53.56785714285714, 53.34571428571427, 51.72499999999999, 52.42535714285714, 51.1342857142857, 52.739999999999995, 54.30464285714286, 56.4325, 56.099642857142854, 57.536785714285706, 58.76571428571428, 59.07678571428571, 59.46857142857142, 59.48142857142857, 58.466071428571425, 59.612142857142864, 59.89964285714286, 60.06464285714286, 60.058928571428574, 61.61714285714286, 62.67928571428572, 63.128928571428574, 62.776071428571434, 62.23107142857143, 60.41071428571429, 61.42892857142857, 58.75678571428572, 59.05035714285714, 58.243571428571435, 59.49178571428572, 60.44321428571429, 60.36, 61.198076923076925, 60.8428, 61.31833333333333, 58.28652173913043, 59.525, 57.607619047619046, 58.267500000000005, 58.17684210526316, 55.10166666666666, 56.77470588235295, 56.816874999999996, 55.336666666666666, 55.75857142857143, 55.2176923076923, 57.673333333333325, 54.23363636363636, 55.364999999999995, 55.717777777777776, 55.08875, 54.30571428571428, 54.83166666666667, 54.96, 62.442499999999995, 65.71666666666667, 80.63499999999999, 53.75]\n",
      "[0.7388888781657883, 0.7387721418472656, 0.7380088584059306, 0.7357044893610979, 0.7335146851048174, 0.7314913205225624, 0.7397521932521526, 0.742034911667167, 0.7438523958573112, 0.7408763693769572, 0.7440700877480831, 0.7440700877480831, 0.7434350367151652, 0.7463760122802071, 0.7406619859435126, 0.7449233715836512, 0.7428296584768426, 0.746227268706731, 0.7409063320483485, 0.7329869359560299, 0.7292723940165287, 0.7268607915050441, 0.7201900081218646, 0.7239295838896397, 0.7216339187860261, 0.7168456334084702, 0.7129034443621751, 0.709574600032395, 0.7148998310012371, 0.7212628967864978, 0.7154926306875109, 0.726353551678426, 0.7213329449794514, 0.720913292538877, 0.71908655569754, 0.7179696780936176, 0.7186833133528562, 0.7240174093570768, 0.7180526882090816, 0.7207811550675668, 0.7222526509524245, 0.7145034111877853, 0.7172018904609224, 0.7172018904609224, 0.7209163991079562, 0.7207118228758581, 0.7281178620049326, 0.7286514495922645, 0.7286514495922645, 0.7356067879993085, 0.7442592551949545, 0.7457431774261697, 0.7482313005950441, 0.7431689222024777, 0.7513077571704763, 0.7563156557029517, 0.7535218638761348, 0.7493598767193168, 0.7532070310343716, 0.7476030236256167, 0.7473089873462815, 0.7513093794767702, 0.7435236879827669, 0.7435236879827669, 0.7416731901877748, 0.7354710848468378, 0.7379876673807493, 0.7443361063823131, 0.7386505684577558, 0.732190210762146, 0.7309493515022716, 0.7432798634758808, 0.7352991357250122, 0.7352991357250122, 0.7305180236759115, 0.7461306625920172, 0.7402970877928302, 0.7343718337358635, 0.7345846689266148, 0.7353896106320316, 0.7455679973208682, 0.749650554235789, 0.7469793172319704, 0.7495885252800792, 0.7472339207129177, 0.74735859622835, 0.742579690866477, 0.740815256881576, 0.7467967125418333, 0.7479068054804593, 0.7489301557274898, 0.7513623472263737, 0.7475778479464613, 0.7535052592889913, 0.7571853694660006, 0.7478594555813577, 0.7544931991137283, 0.7587548466414421, 0.7617463576445554, 0.755262858907689, 0.7599663169534246, 0.761106946418903, 0.7601129401848908, 0.7579276872646348, 0.7637074821415294, 0.7684344244614464, 0.7586291595553026, 0.7594299085163764, 0.7485444941382814, 0.7514754158273691, 0.7496841403407877, 0.7455917310515192, 0.7490018479376419, 0.7488366240031545, 0.7537417230182611, 0.7546202295760899, 0.7493654430151466, 0.7482598382914175, 0.7461130680374873, 0.743666072838945, 0.7398966162032264, 0.7327970006594804, 0.7298529265971632, 0.7355261390211285, 0.7279154281617823, 0.7315942845938201, 0.7243493808522236, 0.7259070050461947, 0.7195857287641835, 0.7232610196874631, 0.729564267034702, 0.7194249593257465, 0.7143555370622324, 0.7143555370622324, 0.7185091476446597, 0.7141347528894895, 0.720828267061639, 0.7212866970564438, 0.7261836660757393, 0.7260105426917733, 0.72026494401208, 0.7223892527229199, 0.7170754887553824, 0.7145874028726674, 0.7220316420780752, 0.7175744259952772, 0.7257367478652389, 0.7221510841299124, 0.7292011517176049, 0.7350018778629488, 0.7348840246240295, 0.7344035371678351, 0.7317672592741544, 0.7376230974519697, 0.7370853742479957, 0.735908054023574, 0.735315040729121, 0.7354260843859728, 0.7300747667931355, 0.7373069217810674, 0.7363396998906244, 0.741119351290212, 0.7465370827388196, 0.7461687404447923, 0.7453474754381945, 0.7471689099413087, 0.7402001240064482, 0.7343449537823432, 0.7411322711618535, 0.7455164445937281, 0.7457936387293423, 0.7466788189362987, 0.7397359279759274, 0.7466174142105062, 0.7462152023376282, 0.7486674375121989, 0.747809101185724, 0.750854475543316, 0.7455544578910539, 0.7454683658599492, 0.7557943113995292, 0.749491792829866, 0.7579932927732094, 0.7528823478702542, 0.7603090559782995, 0.7592742473188092, 0.7603806219465152, 0.761210315454032, 0.7681355160669313, 0.7646432298667717, 0.766363986239276, 0.7620933953028526, 0.7619337725853628, 0.7529849196126434, 0.7611869626751592, 0.7706950933797053, 0.7727779397321898, 0.7677180208441081, 0.7655297024566207, 0.7585875001419943, 0.7639527172520882, 0.7656068078233282, 0.7569869640562134, 0.763094494517526, 0.7640474895689696, 0.7597289033616289, 0.7650623355464291, 0.7645297524556848, 0.7606910008092115, 0.7624569264867865, 0.7573558041293538, 0.7633671417136393, 0.7602727798891927, 0.7549458187117102, 0.7595659036464594, 0.7567347170803194, 0.7519610965710665, 0.7505994413108305, 0.7442142277705254, 0.7584645347260127, 0.7557017735863775, 0.7689477109507439, 0.7651382287364256, 0.7503362819321023, 0.7392005244285825, 0.7331110436999071, 0.7589275336324368, 0.7913885131053766, 0.7936712507322775, 0.7693296183302506, 0.8563334476650305, 0.844069630513912]\n"
     ]
    }
   ],
   "source": [
    "initial_guess = [0.1, 0.5, 50, 40, 15]\n",
    "individual_banister_model = optimize.minimize(optimize_banister,  x0 = initial_guess, bounds=[(0,1),(0,1),(20,50),(20,60),(10,20)])\n",
    "print(individual_banister_model)\n",
    "\n",
    "# Individual Neural Network Model\n",
    "individual_neural_net_model = MLPRegressor(solver='lbfgs', activation='relu', hidden_layer_sizes=[50], random_state=42)\n",
    "print(Block_TSS)\n",
    "print(Offset_Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=[50], random_state=42, solver='lbfgs')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(Block_TSS)\n",
    "arr_Block_TSS = arr.reshape(-1,1)\n",
    "# print(arr_Block_TSS)\n",
    "\n",
    "individual_neural_net_model.fit(arr_Block_TSS, Offset_Performance)\n",
    "# print(individual_neural_net_model.predict(arr_Block_TSS))\n",
    "# individual_neural_net_model_score = individual_neural_net_model.score(arr_Block_TSS, Offset_Performance)\n",
    "# individual_neural_net_model.fit([[]100],[0.5])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
